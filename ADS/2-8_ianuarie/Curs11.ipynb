{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 150px\" src=\"../../imagini/unitbv2.png\"> SIIPA2020- Știința Explorării și Exploatării Datelor - ADS1  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## <center>Curs 11 - Regresori ML</center>\n",
    "**Universitatea Transilvania**<br>\n",
    "**Semestrul I, 2020-2021**<br>\n",
    "**Instructor:** Conf. univ. dr. Teodor &Scedil;tefan B&icirc;ldea<br>\n",
    "**Contact:** teodor.bildea@unitbv.ro<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agenda:\n",
    "\n",
    "> Padure aleatoare de regresie - Random Forest Regression\n",
    "- Functia Python\n",
    "- Parametrii care trebuie adaptati prin grid search\n",
    "- Exemplu\n",
    "- Tema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pădurea aleatoare este un tip de algoritm de învățare cu supervizare bazat pe învățarea prin ansamblu (Ensemble learning). Acesta este un tip de învățare în care se folosesc diferite tipuri de algoritmi sau același algoritm de mai multe ori pentru a forma un model de predicție mai puternic. Algoritmul random forest combină un algoritm de același tip i.e. arbori de regresie, rezultând o pădure, de unde și denumirea „Pădurea aleatoare”. Algoritmul random forest poate fi utilizat atât pentru sarcini de regresie cât și pentru clasificare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cum funcționează algoritmul \n",
    "\n",
    "Următoarele sunt etapele de bază implicate în realizarea algoritmului random forest:\n",
    "\n",
    "1. Alegeți N înregistrări aleatorii din setul de date.\n",
    "2. Construiți un arbore de decizie pe baza acestor N înregistrări.\n",
    "3. Alegeți numărul de arbori dorit în algoritmul dvs. și repetați pașii 1 și 2.\n",
    "4. În cazul unei probleme de regresie, pentru o înregistrare nouă, fiecare copac din pădure prezice o valoare pentru Y (ieșire). Valoarea finală poate fi calculată luând media tuturor valorilor prevăzute de toți arborii din pădure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avantajele utilizării Random Forest\n",
    "\n",
    "> Algoritmul radom forest nu este părtinitor (biased), deoarece există mai mulți arbori și fiecare arbore este instruit pe un subset de date. Practic, algoritmul se bazează pe puterea „mulțimii”; prin urmare, prejudecata generală a algoritmului este redusă.\n",
    "\n",
    "> Acest algoritm este foarte stabil. Chiar dacă un nou punct de date este introdus în setul de date, algoritmul general nu este afectat foarte mult, deoarece datele noi pot avea un impact asupra unui arbore, dar este foarte greu să aibă impact asupra tuturor copacilor.\n",
    "\n",
    "> Algoritmul funcționează bine atunci când aveți caracteristici atât categorice cât și numerice.\n",
    "\n",
    "> Algoritmul funcționează bine și când datele au valori lipsă sau nu au fost scalate bine\n",
    "\n",
    "### Dezavantaje ale utilizării Random Forest\n",
    "\n",
    "> Un dezavantaj major constă în complexitatea lor. Necesită resurse mult mai multe de calcul, din cauza numărului mare de arbori de decizie.\n",
    "\n",
    "> Datorită complexității lor, ei necesită mult mai mult timp pentru a se antrena decât alți algoritmi comparabili."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functia Python  si Parametrii\n",
    "\n",
    "Prezentam in continuare cativa dintre parametrii implementarii din <a href=\"https://https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\" class=\"dc by ii ij ik il\" target=\"_blank\" rel=\"noopener nofollow\">scikit-learn</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_estimators: Numărul de arbori din pădure.\n",
    "\n",
    "- criterion: Funcția de a măsura calitatea unei splitari. Criteriile acceptate sunt „gini” pentru Gini impurity index și „entropie” pentru Information Gain.\n",
    "\n",
    "- max_depth: Adâncimea maximă a copacului. Dacă e `None`, atunci nodurile sunt extinse până când toate frunzele sunt pure sau până când toate frunzele conțin mai puțin de min_samples_split mostre.\n",
    "\n",
    "- min_samples_split: (implicit = 2) Numărul minim de eșantioane necesar pentru a împărți un nod intern:\n",
    "\n",
    "    - Dacă e un număr intreg, atunci acesta va fi considerat drept numărul minim de esantioane.\n",
    "\n",
    "    - Dacă e un float (numar real), atunci min_samples_split este o proportie, iar plafonul (min_samples_split * n_samples) este numărul minim de probe pentru fiecare împărțire.\n",
    "\n",
    "\n",
    "\n",
    "- min_samples_leaf: Numărul minim de eșantioane necesar să fie la un nod frunze. Un punct despărțit la orice adâncime va fi luat în considerare numai dacă lasă cel puțin min_samples_leaf probe de formare în fiecare dintre ramurile din stânga și din dreapta. Aceasta poate avea efectul de a netezi modelul, în special în regresie.\n",
    "\n",
    "    - Dacă e int, atunci consideră min_samples_leaf drept numărul minim.\n",
    "\n",
    "    - Dacă e float, atunci min_samples_leaf este o fracție, iar plafonul (min_samples_leaf * n_samples) este numărul minim de eșantioane pentru fiecare nod.\n",
    "\n",
    "- min_weight_fraction_leaf: Fracția minimă ponderată din suma totală a greutăților (din toate eșantioanele de intrare) necesară pentru a fi la un nod frunze. Probele au o greutate egală atunci când nu este furnizat eșantion_weight.\n",
    "\n",
    "- max_features: int, float, string sau None, opțional (implicit = \"auto\") Numărul de caracteristici care trebuie luate în considerare atunci când căutați cea mai bună împărțire:\n",
    "\n",
    "    - Dacă int, atunci se iau în considerare max_features la fiecare împărțire.\n",
    "\n",
    "    - Dacă float, atunci max_features este o proportie și sunt considerate caracteristici int (max_features * n_features) la fiecare împărțire.\n",
    "\n",
    "    - Dacă „auto”, atunci max_features = sqrt (n_features).\n",
    "\n",
    "    - Dacă „sqrt”, atunci max_features = sqrt (n_features) (la fel ca „auto”).\n",
    "\n",
    "    - Dacă „log2”, max_features = log2 (n_features).\n",
    "\n",
    "    - Dacă Niciuna, atunci max_features = n_features.\n",
    "\n",
    "> Notă: căutarea unei împărțiri nu se oprește până când nu este găsită cel puțin o partiție validă a eșantioanelor nodului, chiar dacă este necesară inspecția eficientă a mai multor funcții max_features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplu\n",
    "\n",
    "Problema de aici este de a prezice consumul de motorină (în milioane de galoane - 1 galon ~ 3.8 L) în 48 de state americane pe baza taxei pe motorină (în centi), venitul pe cap de locuitor (dolari), autostrăzile pavate (în mile) și proporția populației cu permis de conducere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4399</td>\n",
       "      <td>431</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "0         9.0            3571            1976                         0.525   \n",
       "1         9.0            4092            1250                         0.572   \n",
       "2         9.0            3865            1586                         0.580   \n",
       "3         7.5            4870            2351                         0.529   \n",
       "4         8.0            4399             431                         0.544   \n",
       "\n",
       "   Petrol_Consumption  \n",
       "0                 541  \n",
       "1                 524  \n",
       "2                 561  \n",
       "3                 414  \n",
       "4                 410  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('../Curs10/petrol_consumption.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separam datele in atribute (X) si variabila ce urmeaza a fi prezisa (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:4].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impartim in set de date de antrenament si test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalam atributele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antrenam regresorul si testam predictiile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasa <b> RandomForestRegressor </b> din biblioteca `sklearn.ensemble` este utilizată pentru a rezolva problemele de regresie prin pădure aleatoare. Cel mai important parametru al clasei <b>RandomForestRegressor</b> este parametrul `n_estimators`. Acest parametru definește numărul de arbori din pădurea întâmplătoare. Vom începe cu n_estimator = 20 pentru a vedea cum funcționează algoritmul nostru. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pentru problemele de regresie, valorile utilizate pentru evaluarea unui algoritm sunt abaterea medie liniara, abaterea medie pătratică și radicalul ei. Executați următorul cod pentru a găsi aceste valori:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 51.76500000000001\n",
      "Mean Squared Error: 4216.166749999999\n",
      "Root Mean Squared Error: 64.93201637097064\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cu 20 de copaci, eroarea medie în rădăcină este 64,93, care este mai mare de 10 la sută din consumul mediu de benzină, adică 576,77. Acest lucru poate indica, printre altele, că nu am folosit suficient estimatori (copaci).\n",
    "\n",
    "Dacă numărul estimatorilor este modificat la 200, rezultatele sunt următoarele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 48.33899999999999\n",
      "Mean Squared Error: 3494.2330150000003\n",
      "Root Mean Squared Error: 59.112037818028234\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eroarea a scazut. Numarul optim al arborilor din padure trebuie cautat intr-o bucla, incercand antrenare cu diverse valori. Cautarea se poate face manual sau folosind o functie Python.\n",
    "\n",
    "## TEMA -grid search pentru random forest regression\n",
    "\n",
    "Mai jos aveti un model de grid search pentru random forest.\n",
    "\n",
    "Folositi diverse valori pentru parametrii algoritmului - cu alte cuvinte alcatuiti un grid search pentru a determina cea mai buna combinatie pentru datele voastre de antrenament. Prin cea mai buna intelegem acea combinatie pentru care Root Mean Squared Error e minima.\n",
    "\n",
    "Obs: valorile de mai jos sunt orientative. Puteti explora seturi de valori, puteti adauga parametrii in cautare cu valori specifice - de exemplu criteriul folosit la bifurcari.\n",
    "\n",
    "Odata ce ati determinat cea mai buna configuratie de parametrii pe datele de train, construiti modelelul cu acesti parametrii si aplicati-l pe datele de test si vedeti daca ati imbunatatit performanta - cu cat s-a imbunatatit performanta fata de rezultatele de mai sus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# alcatuiti grila de cautare a parametrilor (parameter grid) \n",
    "param_grid = {\n",
    "    'max_features': ['auto'],\n",
    "    'max_samples': [0.2, 0.4, 0.6, 0.8],\n",
    "    'min_samples_split': [5, 10, 50],\n",
    "    'n_estimators': [10, 100, 500, 1000]\n",
    "}\n",
    "# definiti tipul de regresor dorit\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Instantiatiati modelul de 'grid search' cu cross-validare simpla cv = 1\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 2, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cautam cea mai buna configuratie a parametrilor pe datele de antrenament\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_grid = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
